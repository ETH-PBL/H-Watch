{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB - FANN\n",
    "\n",
    "With this file you will create a dataset to train a neural network and then load convert the model to a suitable one for your microcontroller.\n",
    "\n",
    "You have to create a dataset for **at least 3 letters** and then train and validate FANN with it. You have\n",
    "to record each letter **at least 30 times** for the training set, and **at least 10 times** for the validation set.\n",
    "\n",
    "Execute the cell below only one time so that you can install the missing package. If you are working on a K63's computer than you don't need to run it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyserial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now connect with your microcontroller via UART. Please just put the COM number (e.g if \"COM8\" than just write \"8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial.tools.list_ports\n",
    "print('Com ports list:')\n",
    "comPorts = list(serial.tools.list_ports.comports())\n",
    "for comPort in comPorts:\n",
    "    print(comPort)\n",
    "chooseComPort = input('Please insert port number: ')\n",
    "ser = serial.Serial('COM' + chooseComPort, 115200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_data_func(data_to_write):\n",
    "    for element in data_to_write:\n",
    "        file_to_open.write(element + ' ')\n",
    "    file_to_open.write('\\n' + output + '\\n')\n",
    "    return\n",
    "\n",
    "\n",
    "def convert_to_list(value):\n",
    "    value = value.replace(\"b' \", \"\")\n",
    "    return value.split(\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type in the letter you want to record (append **\"_train\"** for training set or **\"_val\"** for the validation set) and assign it a label. <br>\n",
    "**E.g.:** 3 letters: S_train -> 1 0 0, M_train -> 0 1 0, X_train -> 0 0 1, where 1 0 0, 0 1 0, 0 0 1 are the corresponding labels.\n",
    "\n",
    "Create first the training set for all letters and then the validation set.\n",
    "\n",
    "**IMPORTANT:** put a space between each number of the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter = input('Please insert letter to collect data: ')\n",
    "output = input('Please insert output (e.g. 1 0 0 0): ')\n",
    "file_to_open = open('Samples/' + letter + '.dat', 'a')\n",
    "\n",
    "sampleNumber = 1\n",
    "\n",
    "while input('1 - acquire sample, 2 - exit: ') == '1':\n",
    "    print('Sample number: ' + str(sampleNumber))\n",
    "    line = ser.readline()\n",
    "    lineList = convert_to_list(str(line))\n",
    "    del lineList[-1]\n",
    "    print(lineList)\n",
    "    print('Collected ' + str(len(lineList)) + ' data')\n",
    "    take_data_func(lineList)\n",
    "    sampleNumber = sampleNumber + 1\n",
    "\n",
    "print('Close file')\n",
    "file_to_open.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go to the next step only if you alredy collected data for all 3 letters\n",
    "\n",
    "After you collected all the data generate the final datasets for your neural network.\n",
    "\n",
    "1 - Validation Dataset <br>\n",
    "2 - Training Dataset\n",
    "\n",
    "You will find the result in the \"Dataset\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "\n",
    "data = list()\n",
    "test = list()\n",
    "\n",
    "os.chdir(\"Samples\")\n",
    "\n",
    "datasetVersion = input(\"Do you want to create: 1 - validation dataset, 2 - training dataset\")\n",
    "\n",
    "if(datasetVersion == '1'):\n",
    "    dataToSearch = '*_val.dat'\n",
    "else:\n",
    "    dataToSearch = '*_train.dat'\n",
    "\n",
    "for filename in glob.glob(dataToSearch):\n",
    "    file = open(filename)\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines), 2):\n",
    "        data.append(lines[i:i + 2])\n",
    "        test.append(lines[i:i + 2])\n",
    "    file.close()\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "length = len(data)\n",
    "lengthInput = len(data[0][1].strip().replace(' ', ''))\n",
    "folderName = 'Dataset'\n",
    "\n",
    "os.chdir(\"..\")\n",
    "if os.path.isdir(folderName) == False:\n",
    "    os.makedirs(folderName)\n",
    "\n",
    "filename = input('Please insert the file name: ')\n",
    "f = open(folderName + '/' + filename + '.dat', 'w+')\n",
    "f.write('%i %i %i\\n' % (length, 90, lengthInput))\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "        f.write(data[i][j])\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go to the next step only if you alredy created your final dataset\n",
    "\n",
    "This script will generate the library you have to load in your project. <br>\n",
    "You will find all the files in the \"STMFANN\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "fname = input(\"Insert the name of the File without extension: \")\n",
    "\n",
    "try:\n",
    "    netF = open(\"Dataset/\" + fname + \".net\", 'r')\n",
    "    # find out whether it's a fixed or float version\n",
    "    fann = {}\n",
    "    firstL = netF.readline()\n",
    "    fann[\"nettype\"] = \"float\"\n",
    "    if \"FIX\" in firstL:\n",
    "        print(\"nettype: fixed\")\n",
    "        fann[\"nettype\"] = \"int\"\n",
    "    else:\n",
    "        print(\"nettype: float\")\n",
    "\n",
    "\n",
    "    file = netF.readlines()\n",
    "    for line in file:\n",
    "        parts = line.strip('\\n').split('=')\n",
    "\n",
    "        # if it is not split then we have an invalid line without an '='\n",
    "        if(len(parts) != 2):\n",
    "            continue\n",
    "\n",
    "        # neuron and connection data have specifiers we need to remove\n",
    "        if(len(parts[0].split(\" \")) > 1):\n",
    "            parts[0] = parts[0].split(\" \")[0]\n",
    "        \n",
    "        # store all variables in dictionary\n",
    "        fann[parts[0]] = parts[1]\n",
    "\n",
    "    # currently no networks with a connection_rate below 1 are supported\n",
    "    if float(fann[\"connection_rate\"]) < 1.0:\n",
    "        print(\"Currently no networks with a connection_rate below 1.0 are supported\")\n",
    "        exit(-1)\n",
    "\n",
    "    # reformat neurons and connections\n",
    "    fann[\"neurons\"] = fann[\"neurons\"].strip(\"()\\r\\n \").split(\") (\")\n",
    "    fann[\"connections\"] = fann[\"connections\"].strip(\"()\\r\\n \").split(\") (\")\n",
    "\n",
    "    tot_connections = 0\n",
    "    fann[\"generated_neurons\"] = []\n",
    "    for neuron in fann[\"neurons\"]:\n",
    "        neuron = neuron.split(', ')\n",
    "\n",
    "        num_inputs = neuron[0]\n",
    "        activation_function = neuron[1]\n",
    "        activation_steepness = neuron[2]\n",
    "\n",
    "        first_connection = tot_connections\n",
    "        last_connection = first_connection + int(num_inputs)\n",
    "\n",
    "        fann[\"generated_neurons\"].append(\"{\" + ', '.join((str(first_connection), str(last_connection), activation_steepness, activation_function)) + \"}\")\n",
    "\n",
    "        tot_connections = last_connection\n",
    "\n",
    "    if tot_connections != len(fann[\"connections\"]):\n",
    "        print(\"ERROR: tot_connections != len(connections)\")\n",
    "        print(tot_connections)\n",
    "        print(len(fann[\"connections\"]))\n",
    "        exit(-1)\n",
    "\n",
    "    fann[\"generated_connections\"] = []\n",
    "    for connection in fann[\"connections\"]:\n",
    "        connection = connection.split(\", \")\n",
    "        fann[\"generated_connections\"].append(connection[1])\n",
    "\n",
    "    fann[\"generated_layers\"] = []\n",
    "    layer_num = 0\n",
    "    fann['layer_sizes'] = fann['layer_sizes'].strip()\n",
    "    for layer in fann['layer_sizes'].split(' '):\n",
    "        fann[\"generated_layers\"].append('{' + str(layer_num) + ', ' + str(layer_num + int(layer)) + '}')\n",
    "        layer_num = layer_num + int(layer)\n",
    "\n",
    "    if \"decimal_point\" not in fann:\n",
    "        fann['decimal_point'] = \"1\"\n",
    "\n",
    "    fann[\"multiplier\"] = 1 << int(fann[\"decimal_point\"])\n",
    "        \n",
    "    fann[\"num_input\"] = str(int(fann['layer_sizes'].split(' ')[0]) - 1)\n",
    "    fann[\"num_output\"] = str(int(fann['layer_sizes'].strip(' ').split(' ')[-1]) - 1)\n",
    "\n",
    "    # calculate sigmoid functions\n",
    "    multiplier = int(fann[\"multiplier\"])\n",
    "    precalc_fixed = {}\n",
    "    precalc_fixed[\"SIGMOID_RESULTS_0\"] = max(int(multiplier / 200.0 + 0.5), 1)\n",
    "    precalc_fixed[\"SIGMOID_RESULTS_1\"] = max(int(multiplier / 20.0 + 0.5), 1)\n",
    "    precalc_fixed[\"SIGMOID_RESULTS_2\"] = max(int(multiplier / 4.0 + 0.5), 1)\n",
    "    precalc_fixed[\"SIGMOID_RESULTS_3\"] = min(multiplier - int(multiplier / 4.0 + 0.5), multiplier - 1)\n",
    "    precalc_fixed[\"SIGMOID_RESULTS_4\"] = min(multiplier - int(multiplier / 20.0 + 0.5), multiplier - 1)\n",
    "    precalc_fixed[\"SIGMOID_RESULTS_5\"] = min(multiplier - int(multiplier / 200.0 + 0.5), multiplier - 1)\n",
    "\n",
    "    precalc_fixed[\"SIGMOID_SYMMETRIC_RESULTS_0\"] = max(int((multiplier / 100.0) - multiplier - 0.5), int(1 - multiplier))\n",
    "    precalc_fixed[\"SIGMOID_SYMMETRIC_RESULTS_1\"] = max(int((multiplier / 10.0) - multiplier - 0.5), int(1 - multiplier))\n",
    "    precalc_fixed[\"SIGMOID_SYMMETRIC_RESULTS_2\"] = max(int((multiplier / 2.0) - multiplier - 0.5), int(1 - multiplier))\n",
    "    precalc_fixed[\"SIGMOID_SYMMETRIC_RESULTS_3\"] = min(multiplier - int(multiplier / 2.0 + 0.5), multiplier - 1)\n",
    "    precalc_fixed[\"SIGMOID_SYMMETRIC_RESULTS_4\"] = min(multiplier - int(multiplier / 10.0 + 0.5), multiplier - 1)\n",
    "    precalc_fixed[\"SIGMOID_SYMMETRIC_RESULTS_5\"] = min(multiplier - int(multiplier / 100.0 + 0.5), multiplier - 1)\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        precalc_fixed[\"SIGMOID_VALUES_\" + str(i)] = int(((log(multiplier / float(precalc_fixed[\"SIGMOID_RESULTS_\" + str(i)]) - 1) * float(multiplier)) / -2.0) * float(multiplier))\n",
    "        precalc_fixed[\"SIGMOID_SYMMETRIC_VALUES_\" + str(i)] = int(((log((multiplier - float(precalc_fixed[\"SIGMOID_SYMMETRIC_RESULTS_\" + str(i)])) / float(precalc_fixed[\"SIGMOID_SYMMETRIC_RESULTS_\" + str(i)] + multiplier)) * float(multiplier)) / -2.0) * float(multiplier))\n",
    "\n",
    "    # generate file contents for fann_conf.h\n",
    "    saveString = '#ifndef FANN_FANN_CONF_H_\\n'\n",
    "    saveString = saveString + '#define FANN_FANN_CONF_H_\\n\\n'\n",
    "\n",
    "    if fann[\"nettype\"] == \"int\":\n",
    "        saveString = saveString + '#define FIXEDFANN\\n\\n'\n",
    "\n",
    "    for x in precalc_fixed:\n",
    "        saveString = saveString + '#define ' + x + ' ' + str(precalc_fixed[x]) + '\\n'\n",
    "\n",
    "    saveString = saveString + '\\n#define NUM_NEURONS ' + str(len(fann[\"generated_neurons\"])) + '\\n'\n",
    "    saveString = saveString + '#define MULTIPLIER ' + str(fann[\"multiplier\"]) + '\\n'\n",
    "    saveString = saveString + '#define DECIMAL_POINT ' + fann[\"decimal_point\"] + '\\n'\n",
    "    saveString = saveString + '#define NUM_INPUT ' + fann[\"num_input\"] + '\\n'\n",
    "    saveString = saveString + '#define NUM_OUTPUT ' + fann[\"num_output\"] + '\\n'\n",
    "    saveString = saveString + '#define NUM_LAYERS ' + str(len(fann[\"generated_layers\"])) + '\\n'\n",
    "    saveString = saveString + '#define CONNECTION_RATE ' + fann[\"connection_rate\"] + '\\n\\n'\n",
    "\n",
    "    saveString = saveString + '\\n#endif // FANN_FANN_CONF_H_\\n'\n",
    "\n",
    "    try:\n",
    "        FW = open('STMFANN/fann_conf.h', \"w\")\n",
    "        FW.write(saveString)\n",
    "        FW.close()\n",
    "    except IOError:\n",
    "        print(\"Could not open write fann_conf.h\")\n",
    "        exit(1)\n",
    "\n",
    "    # generate file contents for fann_net.h\n",
    "    saveString = '#ifndef FANN_FANN_NET_H_\\n'\n",
    "    saveString = saveString + '#define FANN_FANN_NET_H_\\n\\n'\n",
    "\n",
    "    #insert includes\n",
    "    saveString = saveString + '#include \"fann.h\" \\n'\n",
    "    saveString = saveString + '#include \"fann_structs.h\" \\n\\n'\n",
    "    \n",
    "    saveString = saveString + 'const enum fann_nettype_enum network_type = ' + fann[\"network_type\"] + ';\\n\\n'\n",
    "    saveString = saveString + 'const fann_neuron fann_neurons[' + str(len(fann[\"generated_neurons\"])) + '] = {' + ', '.join(fann[\"generated_neurons\"]) + '};\\n\\n'\n",
    "    saveString = saveString + 'fann_type fann_weights[' + str(len(fann[\"generated_connections\"])) + '] = {' + ', '.join(fann[\"generated_connections\"]) + '};\\n\\n'\n",
    "    saveString = saveString + 'const fann_layer fann_layers[' + str(len(fann[\"generated_layers\"])) + '] = {' + ', '.join(fann[\"generated_layers\"]) + '};\\n\\n'\n",
    "\n",
    "    saveString = saveString + '\\n#endif // FANN_FANN_NET_H_\\n'\n",
    "\n",
    "    try:\n",
    "        FW = open('STMFANN/fann_net.h', \"w\")\n",
    "        FW.write(saveString)\n",
    "        FW.close()\n",
    "    except IOError:\n",
    "        print(\"Could not open write fann_net.h\")\n",
    "        exit(1)\n",
    "\n",
    "    print(\"generated fann_net.h\")\n",
    "    print(\"generated fann_conf.h\")\n",
    "    print(\"NETWORK converted. Please copy the files and/or recompile\")\n",
    "except IOError:\n",
    "    print(\"Could not open \" + fname + \".net\")\n",
    "    print(\"Failed to generate network from file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
